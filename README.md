# ğŸ§  Deep Learning Labs

This repository contains my solutions for all the laboratory exercises of the "Deep Learning" course at the Higher School of Computer Science (08 May 1945), Sidi Bel Abbes, Algeria, for 1st-year Master's students specializing in Artificial Intelligence and Data Science.

## ğŸ“˜ Overview

The labs cover practical applications of Deep Learning, focusing on both theoretical understanding and hands-on implementation using PyTorch.
They include the study of neural network fundamentals, optimization, model evaluation, and modern architectures for image classification.

Main topics include:

### ğŸ§© Neural Network Foundations

- Perceptron and Adaline (ADAptive LInear NEuron) implementations from scratch.

- Multi-Layer Perceptron (MLP) with forward and backward propagation.

- Activation functions (Sigmoid, ReLU, Tanh) and their effects on learning.

- Gradient descent and optimization behavior visualization.

### ğŸ§  Deep Architectures

- Implementation of Feedforward Neural Networks using numpy and torch.

- Understanding Loss Functions, Gradients, and Parameter Updates.

- Regularization (Dropout, Weight Decay) and initialization strategies.

### ğŸ§¬ Convolutional Neural Networks (CNN)

- Designing CNNs for image classification.

- Feature extraction and pooling visualization.

- Training CNNs on small image datasets with performance evaluation.

### ğŸ” Transfer Learning

Using pre-trained models such as:

- EfficientNet_B0

- ShuffleNet_V2_X1_0

- Applying Transfer Learning for feature extraction and fine-tuning.

- Comparing performance between frozen and trainable layers.

### ğŸ§® Model Evaluation & Metrics

- Metrics used:

   1. Accuracy

   2. Precision

   3. Recall

   4. F1-Score

   5. AUROC

- Use of torchmetrics for unified evaluation.

- Confusion matrix visualization and per-class performance analysis.

### ğŸ“ˆ Visualization & Analysis

- Training/validation loss & accuracy curves using Matplotlib/Seaborn.

- Confusion matrices for model performance insight.

- Summary of models using torchsummary.

- Learning rate analysis and convergence comparison.

### ğŸ“¦ Libraries Used

- Python â€“ Core language

- NumPy â€“ Numerical computations

- Pandas â€“ Data manipulation

- Matplotlib / Seaborn â€“ Visualization

- PyTorch â€“ Deep learning framework

- Torchvision â€“ Datasets & pre-trained models

- Torchmetrics â€“ Model evaluation

- Torchsummary â€“ Model architecture summary

- tqdm â€“ Training progress visualization

- scikit-learn â€“ Data splitting and metrics
  
